from bs4 import BeautifulSoup
import requests
import time
import re
import random

start, end = 1000, 1001
project_set = set()

for i in range(start, end):
    url = 'https://scratch.mit.edu/classes/'+ str(i) +'/studios/'
    page = requests.get(url)
    time.sleep(random.uniform(0.5, 0.75))

    soup = BeautifulSoup(page.text, 'html.parser')

    data = soup.find_all("a", href=re.compile("/studios/"))
    # print(len(data))
    time.sleep(0.5)

    for j in range (len(data)):
        href = data[j].get("href")
        studio_number = href.split("/")[2]
        print(studio_number)

        url2 = 'https://scratch.mit.edu/studios/' + str(studio_number) + '/'
        page2 = requests.get(url2)
        time.sleep(random.uniform(0.5, 0.75))

        soup2 = BeautifulSoup(page2.text, 'html.parser')
        print(soup2)
        # data2 = soup.find_all(class_ = 'studio-project-tile')
        # print(len(data2));
        # for k in range (len(data2)):
        #     href2 = data2[k].get("href")
        #     print(href2)
        #     project_number = href.split("/")[2]

        #     project_set.add(project_number)

with open("output.txt", "a") as file:
    for number in project_number:
        file.write(str(number) + "\n")
             